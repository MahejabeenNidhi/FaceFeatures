{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23b4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "from azure.cognitiveservices.vision.face.models import FaceAttributeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f264bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vision API \n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb0a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrive from Face Resource - Resource Management\n",
    "faceKEY = \"1ab3848ea22649299da961e8feb813a4\"\n",
    "faceENDPOINT = \"https://face-rec-app.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4266f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(faceENDPOINT, CognitiveServicesCredentials(faceKEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e3adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrive key and endpoint from Computer Vision Resource\n",
    "compvision_subscription_key = \"834987a3f5ef426e866617fd0739af1e\"\n",
    "compvision_endpoint = \"https://visualpattern.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09de7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an authenticated Computer Vision Client\n",
    "computervision_client = ComputerVisionClient(compvision_endpoint, CognitiveServicesCredentials(compvision_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ce41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes you want returned with the API call, a list of FaceAttributeType enum (string format)\n",
    "face_attributes = ['headPose', 'glasses', 'occlusion', 'blur', 'exposure', 'noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5635dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open(os.path.join(\"C:\\\\Users\\\\nidhimh\\\\Documents\\\\Face\\\\faces\\\\\", \"image_0001.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e94906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = os.path.join (os.path.dirname(os.path.abspath('')), \"faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325ea00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = os.path.join (images_folder, \"image_0001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d432b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image = open(local_image_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc153f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect a face with attributes, returns a list[DetectedFace]\n",
    "detected_faces = face_client.face.detect_with_stream(local_image, return_face_attributes=face_attributes)\n",
    "\n",
    "if not detected_faces:\n",
    "    raise Exception(\n",
    "            'No face detected from image {}'.format(os.path.basename(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b33bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert width height to a point in a rectangle\n",
    "def faceApp():\n",
    "    image=Image.open(os.path.join(\"C:\\\\Users\\\\nidhimh\\\\Documents\\\\Face\\\\faces\\\\\", \"image_0001.jpg\"))\n",
    "    images_folder = os.path.join (os.path.dirname(os.path.abspath('')), \"faces\")\n",
    "    local_image_path = os.path.join (images_folder, \"image_0001.jpg\")\n",
    "    local_image = open(local_image_path, \"rb\")\n",
    "    image_size = Image.open('image_0001.jpg').size\n",
    "    image_width, image_height = image_size\n",
    "    # Detect a face with attributes, returns a list[DetectedFace]\n",
    "    detected_faces = face_client.face.detect_with_stream(local_image, return_face_attributes=face_attributes)\n",
    "    if not detected_faces:\n",
    "        raise Exception(\n",
    "                'No face detected from image {}'.format(os.path.basename(image)))\n",
    "    listofIssues = []\n",
    "    #possible issues\n",
    "    horCentre = 'Face is not horizontally centred'\n",
    "    verCentre = 'Face is not vertically centred'\n",
    "    \n",
    "    def Rectangle(faceDictionary):\n",
    "        rect = faceDictionary.face_rectangle\n",
    "        left = rect.left\n",
    "        top = rect.top\n",
    "        right = left + rect.width\n",
    "        bottom = top + rect.height\n",
    "        rightspace = image_width - right\n",
    "        bottomspace = image_height - bottom \n",
    "           \n",
    "        if abs(left - rightspace) > 50: \n",
    "            listofIssues.append(horCentre)\n",
    "        if abs(top - bottomspace) > 75:\n",
    "            listofIssues.append(verCentre)\n",
    "        return listofIssues\n",
    "    \n",
    "    Rectangle(face)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(listofIssues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9f8e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Face is not horizontally centred', 'Face is not vertically centred']\n"
     ]
    }
   ],
   "source": [
    "faceApp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aaa95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "675603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def something():\n",
    "    list = []\n",
    "    a = 'good'\n",
    "    b = 'bad'\n",
    "    c = 'okay'\n",
    "    x = 3\n",
    "    y = 4\n",
    "    z = 0\n",
    "    if (x + y) > 5:\n",
    "        list.append(a)\n",
    "    if (z + z) < 1:\n",
    "        list.append(c)\n",
    "    if (y + z) < 5:\n",
    "        list.append(b)\n",
    "    print(list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8740205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'okay', 'bad']\n"
     ]
    }
   ],
   "source": [
    "something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1348bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the head_pose data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d4b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pose_string = str(face.face_attributes.head_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edd8c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, y, p = head_pose_string.split(',')\n",
    "roll = r[8:]\n",
    "roll_num = abs(float(roll))\n",
    "yaw = y[7:]\n",
    "yaw_num = abs(float(yaw))\n",
    "pitch = p[9:-1]\n",
    "pitch_num = abs(float(pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56e789af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head and face is correctly positioned\n"
     ]
    }
   ],
   "source": [
    "if roll_num > 5:\n",
    "    print('head is titled to the side')\n",
    "elif yaw_num > 5:\n",
    "    print('face is turned to the side')\n",
    "elif pitch_num > 5:\n",
    "    print('head is foreward or backward titled')\n",
    "else:\n",
    "    print('head and face is correctly positioned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b80fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_string = str(face.face_attributes.glasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472f3cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face does not have glasses\n"
     ]
    }
   ],
   "source": [
    "if glasses_string.__contains__(\"no_glasses\") == False:\n",
    "    print('Face is obstructed by glasses')\n",
    "else:\n",
    "    print('Face does not have glasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f8d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes are not occluded\n"
     ]
    }
   ],
   "source": [
    "if face.face_attributes.occlusion.eye_occluded == True:\n",
    "    print('Eyes are occluded')\n",
    "else:\n",
    "    print('Eyes are not occluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7705ae6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forehead is not occluded\n"
     ]
    }
   ],
   "source": [
    "if face.face_attributes.occlusion.forehead_occluded == True:\n",
    "    print('Forehead is occluded')\n",
    "else:\n",
    "    print('Forehead is not occluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb01e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import glob\n",
    "\n",
    "from resize import your_resize_function\n",
    "\n",
    "for image_file in glob.iglob('/path/to/image/dir/*.jpg'):\n",
    "    your_resize_function(image_file)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
