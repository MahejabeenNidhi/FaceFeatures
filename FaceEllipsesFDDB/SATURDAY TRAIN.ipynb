{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c7f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import imgaug\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "from math import pi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from fnmatch import fnmatch\n",
    "from itertools import permutations\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e660b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"C:\\\\Users\\\\nidhimh\\\\Documents\\\\Mask_RCNN-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c548e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.config import Config\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c36b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           FDDB\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class FDDBConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy  dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"FDDB\"\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + face\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "config = FDDBConfig()\n",
    "config.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9c341c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDDBDataset(utils.Dataset):\n",
    "\n",
    "    def load_FDDB(self, dataset_dir, subset):\n",
    "        \"\"\"\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"face\", 1, \"face\")\n",
    "        \n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Load annotations\n",
    "        data = pd.read_csv('dataforfold2.csv', index_col=0)\n",
    "        \n",
    "        unique = list(dict.fromkeys(list(data['imgPath'])))\n",
    "        for a in unique:\n",
    "            sub = data[data['imgPath'] == a]\n",
    "            sub = sub.iloc[:, 1:]\n",
    "            l = sub.values.tolist()\n",
    "            ellipses = {'imgPath': a, 'parameters': l}\n",
    "            a += '.jpg'\n",
    "            filename = os.path.basename(a[15:])\n",
    "            image_path = os.path.join('C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\val', filename)\n",
    "\n",
    "            # load_mask() needs the image size to convert polygons to masks.\n",
    "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
    "            # the image. This is only managable since the dataset is tiny.\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"face\",\n",
    "                image_id=filename,  # use file name as a unique image id\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=ellipses,\n",
    "                intances = int(len(ellipses['parameters']))\n",
    "            )\n",
    "                \n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"face\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "            \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "        one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        ellipse = info[\"polygons\"]\n",
    "        \n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "                dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            rr, cc = skimage.draw.ellipse(p['center_y'], p['center_x'], p['rad_y'], p['rad_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73597727",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FDDBDataset()\n",
    "dataset_train.load_FDDB('C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset', \"train\")\n",
    "dataset_train.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebfe749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = FDDBDataset()\n",
    "dataset_val.load_FDDB('C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset', \"val\")\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609d9a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07acf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b24e49b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\logs\\fddb20210703T1951\\mask_rcnn_fddb_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "ERROR:root:Error processing image {'id': 'img_407.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_407.jpg', 'width': 449, 'height': 377, 'polygons': {'imgPath': '2002/08/04/big/img_407', 'parameters': [[33.528889, 23.135402, -1.46258, 51.156104, 173.184995], [30.909747, 21.983037, 1.551574, 8.91358, 65.935022], [31.774451, 18.555769, 1.492074, 50.80299, 4.443433], [85.67369, 55.936901, -1.343675, 167.317165, 104.467609], [41.4311, 30.154598, -1.51822, 360.953151, 328.984383], [37.144461, 27.380038, -1.483926, 421.885057, 176.003284]]}, 'intances': 6}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n",
      "ERROR:root:Error processing image {'id': 'img_301.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_301.jpg', 'width': 450, 'height': 440, 'polygons': {'imgPath': '2002/08/13/big/img_301', 'parameters': [[95.889242, 63.425789, -1.315467, 218.609878, 121.516098]]}, 'intances': 1}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n",
      "ERROR:root:Error processing image {'id': 'img_258.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_258.jpg', 'width': 450, 'height': 448, 'polygons': {'imgPath': '2002/08/11/big/img_258', 'parameters': [[57.807612, 35.558183, -1.558006, 195.592969, 106.783771], [18.1515, 11.592792, -1.537889, 275.802184, 420.729368], [20.470656, 13.565436, 1.406736, 350.376873, 417.56531], [17.042057, 11.369755, -1.554118, 293.66, 368.0], [15.223555, 11.212343, -1.560541, 28.701937, 263.132637], [13.2708, 10.3214, 1.561045, 360.069796, 127.465736]]}, 'intances': 6}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n",
      "ERROR:root:Error processing image {'id': 'img_1347.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_1347.jpg', 'width': 358, 'height': 450, 'polygons': {'imgPath': '2002/08/01/big/img_1347', 'parameters': [[105.251752, 67.716508, -1.567968, 196.57136, 165.268997]]}, 'intances': 1}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n",
      "ERROR:root:Error processing image {'id': 'img_961.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_961.jpg', 'width': 450, 'height': 327, 'polygons': {'imgPath': '2002/07/31/big/img_961', 'parameters': [[68.722452, 47.448581, 1.540624, 135.416382, 95.183653]]}, 'intances': 1}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n",
      "ERROR:root:Error processing image {'id': 'img_533.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_533.jpg', 'width': 269, 'height': 410, 'polygons': {'imgPath': '2002/08/02/big/img_533', 'parameters': [[126.707387, 75.551435, -1.554628, 153.807558, 162.914902]]}, 'intances': 1}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
      "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
      "KeyError: 'instances'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'instances'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-83fb3ae74319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             layers='heads')\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[0;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2374\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2375\u001b[0m         )\n\u001b[0;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2192\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2193\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2194\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2196\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\u001b[0m in \u001b[0;36mdata_generator\u001b[1;34m(dataset, config, shuffle, augment, augmentation, random_rois, batch_size, detection_targets, no_augmentation_sources)\u001b[0m\n\u001b[0;32m   1707\u001b[0m                     load_image_gt(dataset, config, image_id, augment=augment,\n\u001b[0;32m   1708\u001b[0m                                 \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1709\u001b[1;33m                                 use_mini_mask=config.USE_MINI_MASK)\n\u001b[0m\u001b[0;32m   1710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m             \u001b[1;31m# Skip images that have no instances. This can happen in cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\u001b[0m in \u001b[0;36mload_image_gt\u001b[1;34m(dataset, config, image_id, augment, augmentation, use_mini_mask)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     \u001b[1;31m# Load image and mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m     \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m     \u001b[0moriginal_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m     image, window, scale, padding, crop = utils.resize_image(\n",
      "\u001b[1;32m<ipython-input-10-348863a1dc59>\u001b[0m in \u001b[0;36mload_mask\u001b[1;34m(self, image_id)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# Convert polygons to a bitmap mask of shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n\u001b[0m\u001b[0;32m     63\u001b[0m                 dtype=np.uint8)\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"polygons\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'instances'"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f025788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Starting at epoch 0. LR=0.001\n",
    "\n",
    "Checkpoint Path: C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\logs\\fddb20210703T1951\\mask_rcnn_fddb_{epoch:04d}.h5\n",
    "Selecting layers to train\n",
    "fpn_c5p5               (Conv2D)\n",
    "fpn_c4p4               (Conv2D)\n",
    "fpn_c3p3               (Conv2D)\n",
    "fpn_c2p2               (Conv2D)\n",
    "fpn_p5                 (Conv2D)\n",
    "fpn_p2                 (Conv2D)\n",
    "fpn_p3                 (Conv2D)\n",
    "fpn_p4                 (Conv2D)\n",
    "In model:  rpn_model\n",
    "    rpn_conv_shared        (Conv2D)\n",
    "    rpn_class_raw          (Conv2D)\n",
    "    rpn_bbox_pred          (Conv2D)\n",
    "mrcnn_mask_conv1       (TimeDistributed)\n",
    "mrcnn_mask_bn1         (TimeDistributed)\n",
    "mrcnn_mask_conv2       (TimeDistributed)\n",
    "mrcnn_mask_bn2         (TimeDistributed)\n",
    "mrcnn_class_conv1      (TimeDistributed)\n",
    "mrcnn_class_bn1        (TimeDistributed)\n",
    "mrcnn_mask_conv3       (TimeDistributed)\n",
    "mrcnn_mask_bn3         (TimeDistributed)\n",
    "mrcnn_class_conv2      (TimeDistributed)\n",
    "mrcnn_class_bn2        (TimeDistributed)\n",
    "mrcnn_mask_conv4       (TimeDistributed)\n",
    "mrcnn_mask_bn4         (TimeDistributed)\n",
    "mrcnn_bbox_fc          (TimeDistributed)\n",
    "mrcnn_mask_deconv      (TimeDistributed)\n",
    "mrcnn_class_logits     (TimeDistributed)\n",
    "mrcnn_mask             (TimeDistributed)\n",
    "WARNING:tensorflow:From C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Use tf.cast instead.\n",
    "C:\\Users\\nidhimh\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
    "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
    "ERROR:root:Error processing image {'id': 'img_407.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_407.jpg', 'width': 449, 'height': 377, 'polygons': {'imgPath': '2002/08/04/big/img_407', 'parameters': [[33.528889, 23.135402, -1.46258, 51.156104, 173.184995], [30.909747, 21.983037, 1.551574, 8.91358, 65.935022], [31.774451, 18.555769, 1.492074, 50.80299, 4.443433], [85.67369, 55.936901, -1.343675, 167.317165, 104.467609], [41.4311, 30.154598, -1.51822, 360.953151, 328.984383], [37.144461, 27.380038, -1.483926, 421.885057, 176.003284]]}, 'intances': 6}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "ERROR:root:Error processing image {'id': 'img_301.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_301.jpg', 'width': 450, 'height': 440, 'polygons': {'imgPath': '2002/08/13/big/img_301', 'parameters': [[95.889242, 63.425789, -1.315467, 218.609878, 121.516098]]}, 'intances': 1}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "ERROR:root:Error processing image {'id': 'img_258.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_258.jpg', 'width': 450, 'height': 448, 'polygons': {'imgPath': '2002/08/11/big/img_258', 'parameters': [[57.807612, 35.558183, -1.558006, 195.592969, 106.783771], [18.1515, 11.592792, -1.537889, 275.802184, 420.729368], [20.470656, 13.565436, 1.406736, 350.376873, 417.56531], [17.042057, 11.369755, -1.554118, 293.66, 368.0], [15.223555, 11.212343, -1.560541, 28.701937, 263.132637], [13.2708, 10.3214, 1.561045, 360.069796, 127.465736]]}, 'intances': 6}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "ERROR:root:Error processing image {'id': 'img_1347.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_1347.jpg', 'width': 358, 'height': 450, 'polygons': {'imgPath': '2002/08/01/big/img_1347', 'parameters': [[105.251752, 67.716508, -1.567968, 196.57136, 165.268997]]}, 'intances': 1}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "ERROR:root:Error processing image {'id': 'img_961.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_961.jpg', 'width': 450, 'height': 327, 'polygons': {'imgPath': '2002/07/31/big/img_961', 'parameters': [[68.722452, 47.448581, 1.540624, 135.416382, 95.183653]]}, 'intances': 1}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "ERROR:root:Error processing image {'id': 'img_533.jpg', 'source': 'face', 'path': 'C:\\\\Users\\\\nidhimh\\\\Documents\\\\MaskRCNN\\\\dataset\\\\train\\\\img_533.jpg', 'width': 269, 'height': 410, 'polygons': {'imgPath': '2002/08/02/big/img_533', 'parameters': [[126.707387, 75.551435, -1.554628, 153.807558, 162.914902]]}, 'intances': 1}\n",
    "Traceback (most recent call last):\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1709, in data_generator\n",
    "    use_mini_mask=config.USE_MINI_MASK)\n",
    "  File \"C:\\Users\\nidhimh\\Documents\\Mask_RCNN-master\\mrcnn\\model.py\", line 1212, in load_image_gt\n",
    "    mask, class_ids = dataset.load_mask(image_id)\n",
    "  File \"<ipython-input-10-348863a1dc59>\", line 62, in load_mask\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "KeyError: 'instances'\n",
    "Epoch 1/1\n",
    "---------------------------------------------------------------------------\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "<ipython-input-16-83fb3ae74319> in <module>\n",
    "      6             learning_rate=config.LEARNING_RATE,\n",
    "      7             epochs=1,\n",
    "----> 8             layers='heads')\n",
    "\n",
    "~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py in train(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\n",
    "   2372             max_queue_size=100,\n",
    "   2373             workers=workers,\n",
    "-> 2374             use_multiprocessing=True,\n",
    "   2375         )\n",
    "   2376         self.epoch = max(self.epoch, epochs)\n",
    "\n",
    "~\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\keras\\legacy\\interfaces.py in wrapper(*args, **kwargs)\n",
    "     89                 warnings.warn('Update your `' + object_name +\n",
    "     90                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n",
    "---> 91             return func(*args, **kwargs)\n",
    "     92         wrapper._original_function = func\n",
    "     93         return wrapper\n",
    "\n",
    "~\\Anaconda3\\envs\\MaskRCNN\\lib\\site-packages\\keras\\engine\\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\n",
    "   2192                 batch_index = 0\n",
    "   2193                 while steps_done < steps_per_epoch:\n",
    "-> 2194                     generator_output = next(output_generator)\n",
    "   2195 \n",
    "   2196                     if not hasattr(generator_output, '__len__'):\n",
    "\n",
    "~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py in data_generator(dataset, config, shuffle, augment, augmentation, random_rois, batch_size, detection_targets, no_augmentation_sources)\n",
    "   1707                     load_image_gt(dataset, config, image_id, augment=augment,\n",
    "   1708                                 augmentation=augmentation,\n",
    "-> 1709                                 use_mini_mask=config.USE_MINI_MASK)\n",
    "   1710 \n",
    "   1711             # Skip images that have no instances. This can happen in cases\n",
    "\n",
    "~\\Documents\\Mask_RCNN-master\\mrcnn\\model.py in load_image_gt(dataset, config, image_id, augment, augmentation, use_mini_mask)\n",
    "   1210     # Load image and mask\n",
    "   1211     image = dataset.load_image(image_id)\n",
    "-> 1212     mask, class_ids = dataset.load_mask(image_id)\n",
    "   1213     original_shape = image.shape\n",
    "   1214     image, window, scale, padding, crop = utils.resize_image(\n",
    "\n",
    "<ipython-input-10-348863a1dc59> in load_mask(self, image_id)\n",
    "     60 \n",
    "     61         # Convert polygons to a bitmap mask of shape\n",
    "---> 62         mask = np.zeros([info[\"height\"], info[\"width\"], info[\"instances\"]],\n",
    "     63                 dtype=np.uint8)\n",
    "     64         for i, p in enumerate(info[\"polygons\"]):\n",
    "\n",
    "KeyError: 'instances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0595e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
