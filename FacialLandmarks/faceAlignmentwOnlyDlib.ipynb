{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7db5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import dlib\n",
    "import json\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "from math import pi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "from fnmatch import fnmatch\n",
    "from itertools import permutations\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83124e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagepath = \"C:\\\\Users\\\\nidhimh\\\\Documents\\\\samples\\\\positive\\\\12.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50be17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dlib's shape predictor\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d49ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(imagepath)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8286bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = np.size(img, 0)\n",
    "width = np.size(img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91b1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# Detecting faces in the grayscale image\n",
    "faces = detector(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e541726",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(p)\n",
    "# Get the shape using the predictor\n",
    "for face in faces:\n",
    "    landmarks=predictor(gray, face)\n",
    "for n in range(0,68):\n",
    "    x=landmarks.part(n).x\n",
    "    y=landmarks.part(n).y\n",
    "    cv.circle(img, (x, y), 1, (0, 0, 255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c2bec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv.imshow('seelandmarks', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75fe14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining x and y coordinates of a specific point\n",
    "#x=landmarks.part(30).x\n",
    "#y=landmarks.part(30).y\n",
    "# Drawing a circle\n",
    "#cv.circle(img, (x, y), 6, (0, 0, 255), -1)\n",
    "#cv.imshow('what', img)\n",
    "#cv.waitKey(0)\n",
    "#cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8ee4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "#JAWLINE POINTS: 1 – 17\n",
    "#RIGHT EYEBROW POINTS: 17 – 22\n",
    "#LEFT EYEBROW POINTS: 22 – 27\n",
    "#NOSE BRIDGE POINTS: 27 – 31\n",
    "#LOWER NOSE POINTS: 31 – 36\n",
    "#RIGHT EYE POINTS: 36 – 42\n",
    "#LEFT EYE POINTS: 42 – 48\n",
    "#LEFT EYE POINTS: 42 – 48\n",
    "#MOUTH INNER POINTS: 61 – 68\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a83fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining x and y coordinates of left and right edge of face\n",
    "leftx=landmarks.part(0).x\n",
    "rightx=landmarks.part(16).x\n",
    "rightside = width - rightx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cb3e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontally centered\n"
     ]
    }
   ],
   "source": [
    "# horizontally centered\n",
    "if abs(leftx-rightside) < 0.15*max(leftx, rightside):\n",
    "    print('horizontally centered')\n",
    "else:\n",
    "    print('not horizontally centered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74fd70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distance between the eyebrows and the top of the head is half the distance from the eyebrow to the chin plus allowance for hair\n",
    "# Estimate the crown of the head and calculate whether the face (top of head to chin) covers at least 60% of the image\n",
    "\n",
    "# Find the maximum point of the eyebrows and y coord of chin\n",
    "browpoint = max(landmarks.part(19).y, landmarks.part(24).y)\n",
    "chiny = landmarks.part(8).y\n",
    "\n",
    "browtochin = abs(browpoint -  chiny)\n",
    "\n",
    "crowntochin = browtochin * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae52afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "facePercent = crowntochin/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc41829e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face is covering an adequate percent of image\n"
     ]
    }
   ],
   "source": [
    "if facePercent<0.6:\n",
    "    print('face is too far away')\n",
    "else:\n",
    "    print('face is covering an adequate percent of image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6936df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(imagepath);\n",
    "size = img.shape\n",
    "\n",
    "image_points = np.array([\n",
    "                        (landmarks.part(30).x, landmarks.part(30).y),     # Nose tip\n",
    "                        (landmarks.part(8).x, landmarks.part(8).y),       # Chin\n",
    "                        (landmarks.part(36).x, landmarks.part(36).y),     # Left eye left corner\n",
    "                        (landmarks.part(45).x, landmarks.part(45).y),     # Right eye right corne\n",
    "                        (landmarks.part(48).x, landmarks.part(48).y),     # Left Mouth corner\n",
    "                        (landmarks.part(54).x, landmarks.part(54).y)      # Right mouth corner\n",
    "                    ], dtype=\"double\")\n",
    "\n",
    "    \n",
    "\n",
    "                        \n",
    "model_points = np.array([\n",
    "                        (0.0, 0.0, 0.0),             # Nose tip\n",
    "                        (0.0, -330.0, -65.0),        # Chin\n",
    "                        (-165.0, 170.0, -135.0),     # Left eye left corner\n",
    "                        (165.0, 170.0, -135.0),      # Right eye right corne\n",
    "                        (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                        (150.0, -150.0, -125.0)      # Right mouth corner                         \n",
    "                    ])\n",
    "\n",
    "# Camera internals\n",
    " \n",
    "center = (size[1]/2, size[0]/2)\n",
    "focal_length = center[0] / np.tan(60/2 * np.pi / 180)\n",
    "camera_matrix = np.array(\n",
    "                        [[focal_length, 0, center[0]],\n",
    "                        [0, focal_length, center[1]],\n",
    "                        [0, 0, 1]], dtype = \"double\"\n",
    "                        )\n",
    "\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "(success, rotation_vector, translation_vector) = cv.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    \n",
    "axis = np.float32([[500,0,0], \n",
    "                        [0,500,0], \n",
    "                        [0,0,500]])\n",
    "                          \n",
    "imgpts, jac = cv.projectPoints(axis, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "modelpts, jac2 = cv.projectPoints(model_points, rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "rvec_matrix = cv.Rodrigues(rotation_vector)[0]\n",
    "\n",
    "proj_matrix = np.hstack((rvec_matrix, translation_vector))\n",
    "eulerAngles = cv.decomposeProjectionMatrix(proj_matrix)[6] \n",
    "\n",
    "    \n",
    "pitch, yaw, roll = [math.radians(_) for _ in eulerAngles]\n",
    "\n",
    "\n",
    "pitch = math.degrees(math.asin(math.sin(pitch)))\n",
    "roll = -math.degrees(math.asin(math.sin(roll)))\n",
    "yaw = math.degrees(math.asin(math.sin(yaw)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb7f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head pose is acceptable\n"
     ]
    }
   ],
   "source": [
    "if abs(pitch) > 15:\n",
    "    print('Head is tilted')\n",
    "elif abs(roll) > 15:\n",
    "    print('Head is tilted')\n",
    "elif abs(yaw) > 15:\n",
    "    print('Head is tilted')\n",
    "else:\n",
    "    print('Head pose is acceptable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9bc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5270b65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
