{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23b4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
    "from azure.cognitiveservices.vision.face.models import FaceAttributeType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f264bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import vision API \n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb0a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrive from Face Resource - Resource Management\n",
    "faceKEY = \"1ab3848ea22649299da961e8feb813a4\"\n",
    "faceENDPOINT = \"https://face-rec-app.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4266f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "face_client = FaceClient(faceENDPOINT, CognitiveServicesCredentials(faceKEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e3adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrive key and endpoint from Computer Vision Resource\n",
    "compvision_subscription_key = \"834987a3f5ef426e866617fd0739af1e\"\n",
    "compvision_endpoint = \"https://visualpattern.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09de7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an authenticated Computer Vision Client\n",
    "computervision_client = ComputerVisionClient(compvision_endpoint, CognitiveServicesCredentials(compvision_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ce41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes you want returned with the API call, a list of FaceAttributeType enum (string format)\n",
    "face_attributes = ['headPose', 'glasses', 'occlusion', 'blur', 'exposure', 'noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b33bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert width height to a point in a rectangle\n",
    "def faceApp(image):\n",
    "    local_image = open(image, \"rb\")\n",
    "    image_size = Image.open(image).size\n",
    "    image_width, image_height = image_size\n",
    "    # Detect a face with attributes, returns a list[DetectedFace]\n",
    "    detected_faces = face_client.face.detect_with_stream(local_image, return_face_attributes=face_attributes)\n",
    "    if not detected_faces:\n",
    "        raise Exception(\n",
    "                'No face detected from image {}'.format(os.path.basename(image)))\n",
    "    listofIssues = []\n",
    "    \n",
    "    #possible issues\n",
    "    \n",
    "    horCentre = 'Face is not horizontally centred'\n",
    "    verCentre = 'Face is not vertically centred'\n",
    "    horverCentred = 'Face is horizontally and vertically centred'\n",
    "    horverNotCentred = 'Face is neither horizontally or vertically centred'\n",
    "    \n",
    "    rolled = 'head is tilted to the side'\n",
    "    yawed = 'face is turned to the side'\n",
    "    pitched = 'head is foreward or backward titled'\n",
    "    tiltCentred = 'head and face is correctly positioned'\n",
    "    rolledYawed = 'head is tilted to the side and face is turned to the side'\n",
    "    rolledPitched = 'head is tilted to the side and head is foreward or backward tilted'\n",
    "    pitchedYawed = 'head is foreward or backward tilted and face is turned to the side'\n",
    "    rolledYawedPitched = 'head is tilted to the side, face is turned to the side, and head is forward or backward tilted'\n",
    "    \n",
    "    glasses = 'Face is obstructed by glasses'\n",
    "    noGlasses = 'Face does not have glasses'\n",
    "    \n",
    "    eyesCovered = 'Eyes are occluded'\n",
    "    eyesVisible = 'Eyes are not occluded'\n",
    "    \n",
    "    foreheadCovered = 'Forehead is occluded'\n",
    "    foreheadVisible = 'Forehead is not occluded'\n",
    "    \n",
    "    for face in detected_faces:\n",
    "        rect = face.face_rectangle\n",
    "        left = rect.left\n",
    "        top = rect.top\n",
    "        right = left + rect.width\n",
    "        bottom = top + rect.height\n",
    "        rightspace = image_width - right\n",
    "        bottomspace = image_height - bottom \n",
    "           \n",
    "        if (abs(left - rightspace) > 50) and (abs(top - bottomspace) >75):\n",
    "            listofIssues.append(horverNotCentred)\n",
    "        elif abs(left - rightspace) > 50: \n",
    "            listofIssues.append(horCentre)\n",
    "        elif abs(top - bottomspace) > 75:\n",
    "            listofIssues.append(verCentre)\n",
    "        else:\n",
    "            listofIssues.append(horverCentred)\n",
    "    \n",
    "    head_pose_string = str(face.face_attributes.head_pose)\n",
    "    a, r, y, p = head_pose_string.split(',')\n",
    "    roll = r[8:]\n",
    "    roll_num = abs(float(roll))\n",
    "    yaw = y[7:]\n",
    "    yaw_num = abs(float(yaw))\n",
    "    pitch = p[9:-1]\n",
    "    pitch_num = abs(float(pitch))\n",
    "    \n",
    "    if (roll_num > 5) and (yaw_num > 5) and (pitch_num > 5):\n",
    "        listofIssues.append(rolledYawedPitched)\n",
    "    elif (roll_num > 5) and (yaw_num > 5):\n",
    "        listofIssues.append(rolledYawed)\n",
    "    elif (roll_num > 5) and (pitch_num > 5):\n",
    "        listofIssues.append(rolledPitched)\n",
    "    elif (yaw_num > 5) and (pitch_num > 5):\n",
    "        listofIssues.append(pitchedYawed)\n",
    "    elif roll_num > 5:\n",
    "        listofIssues.append(rolled)\n",
    "    elif yaw_num > 5:\n",
    "        listofIssues.append(yawed)\n",
    "    elif pitch_num > 5:\n",
    "        listofIssues.append(pitched)\n",
    "    else:\n",
    "        listofIssues.append(tiltCentred)\n",
    "        \n",
    "    glasses_string = str(face.face_attributes.glasses)\n",
    "    if glasses_string.__contains__(\"no_glasses\") == True:\n",
    "        listofIssues.append(noGlasses)\n",
    "    else:\n",
    "        listofIssues.append(glasses)\n",
    "        \n",
    "    if face.face_attributes.occlusion.eye_occluded == True:\n",
    "        listofIssues.append(eyesCovered)\n",
    "    else:\n",
    "        listofIssues.append(eyesVisible)\n",
    "        \n",
    "    if face.face_attributes.occlusion.forehead_occluded == True:\n",
    "        listofIssues.append(foreheadCovered)\n",
    "    else:\n",
    "        listofIssues.append(foreheadVisible)\n",
    "    \n",
    "    print(listofIssues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f8e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'face is turned to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head is foreward or backward titled', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not vertically centred', 'head is foreward or backward titled', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head is foreward or backward titled', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head and face is correctly positioned', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'head is foreward or backward titled', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not vertically centred', 'head is titled to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not vertically centred', 'face is turned to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'face is turned to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not horizontally centred', 'face is turned to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n",
      "['Face is not vertically centred', 'face is turned to the side', 'Face does not have glasses', 'Eyes are not occluded', 'Forehead is not occluded']\n"
     ]
    },
    {
     "ename": "APIErrorException",
     "evalue": "(429) Requests to the Face - Detect Operation under Face API - v1.0 have exceeded rate limit of your current Face F0 pricing tier. Please retry after 46 seconds. To increase your rate limit switch to a paid tier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-584591687615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\nidhimh\\\\Documents\\\\Face\\\\faces\\\\*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfaceApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-e63721e7a1ed>\u001b[0m in \u001b[0;36mfaceApp\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimage_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Detect a face with attributes, returns a list[DetectedFace]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdetected_faces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_with_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_face_attributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_attributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdetected_faces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         raise Exception(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\cognitiveservices\\vision\\face\\operations\\_face_operations.py\u001b[0m in \u001b[0;36mdetect_with_stream\u001b[1;34m(self, image, return_face_id, return_face_landmarks, return_face_attributes, recognition_model, return_recognition_model, detection_model, face_id_time_to_live, custom_headers, raw, callback, **operation_config)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAPIErrorException\u001b[0m: (429) Requests to the Face - Detect Operation under Face API - v1.0 have exceeded rate limit of your current Face F0 pricing tier. Please retry after 46 seconds. To increase your rate limit switch to a paid tier."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for image_file in glob.iglob('C:\\\\Users\\\\nidhimh\\\\Documents\\\\Face\\\\faces\\\\*.jpg'):\n",
    "    faceApp(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5c388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
